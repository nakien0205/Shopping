{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea5cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "train = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"text-corpus\")\n",
    "test = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"question-answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1494a19",
   "metadata": {},
   "source": [
    "### Run the cell below if you don't use embed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5bdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a5757be12e4a0d992b498f51322c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vector_db = []\n",
    "# import tqdm.notebook as tn\n",
    "\n",
    "# def store_embed():\n",
    "#     for i in tn.tqdm(range(3200)):\n",
    "#         phrase = train['passages'][i]['passage']\n",
    "#         embed = ollama.embed('llama3.2:1B', phrase)['embeddings'][0]\n",
    "#         vector_db.append((phrase, embed))\n",
    "#     return\n",
    "\n",
    "# store_embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474dea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = pd.read_csv('embed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1b30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "db = []\n",
    "vector_db['1'] = vector_db['1'].apply(ast.literal_eval)  # Convert string representation of list to actual list\n",
    "for i in range(3200):\n",
    "    chunk = vector_db['0'][i]\n",
    "    embed = vector_db['1'][i]\n",
    "    db.append((chunk, embed))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    # Don't know why but using cuda is slower than cpu\n",
    "    \n",
    "    a_tensor = torch.tensor(a, dtype=torch.float32)\n",
    "    b_tensor = torch.tensor(b, dtype=torch.float32)\n",
    "\n",
    "    return torch.nn.functional.cosine_similarity(a_tensor, b_tensor, dim=0).item()\n",
    "\n",
    "\n",
    "def retrieve(query, top_n=3):\n",
    "    similarity = []\n",
    "    query_embed = ollama.embed('llama3.2:1B', query)['embeddings'][0]\n",
    "\n",
    "    for phrase, embeds in db:\n",
    "        sim_score = cosine_sim(query_embed, embeds)\n",
    "        similarity.append((phrase, sim_score))\n",
    "\n",
    "    similarity.sort(key=lambda x: x[1], reverse=True) # Sort second element\n",
    "    return similarity[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2d3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took to retrieve: 1.7051129341125488\n",
      "Retrieved knowledge:\n",
      " - (similarity: 0.72) Sixteen months before his death, his son, John Quincy Adams, became the sixth President of the United States (1825 1829), the only son of a former President to hold the office until George W. Bush in 2001.\n",
      " - (similarity: 0.72) Lincoln closely supervised the victorious war effort, especially the selection of top generals, including Ulysses S. Grant. Historians have concluded that he handled the factions of the Republican Party well, bringing leaders of each faction into his cabinet and forcing them to cooperate. Lincoln successfully defused a war scare with the United Kingdom in 1861. Under his leadership, the Union took control of the border slave states at the start of the war. Additionally, he managed his own reelection in the 1864 presidential election.\n",
      " - (similarity: 0.71) John Adams remains the longest-lived person ever elected to both of the highest offices in the United States.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "top_chunk = []\n",
    "input_query = 'Was Abraham Lincoln the sixteenth President of the United States?'\n",
    "\n",
    "start = time.time()\n",
    "retrieve_knowledge = retrieve(input_query)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time took to retrieve: {end - start}')\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for chunk, similarity in retrieve_knowledge:\n",
    "    print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
    "    top_chunk.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5ef38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "No, Abraham Lincoln was not the sixteenth President of the United States. He was the 16th President, serving from 1861 until his assassination in 1865."
     ]
    }
   ],
   "source": [
    "instruction_prompt = f'''\n",
    "You are a helpful chatbot that gives a concise and short answer.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{' '.join(chunk for chunk in top_chunk)}\n",
    "'''\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model='llama3.2:1B',\n",
    "    messages=[\n",
    "      {'role': 'system', 'content': instruction_prompt},\n",
    "      {'role': 'user', 'content': input_query},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# print the response from the chatbot in real-time\n",
    "print('Chatbot response:')\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
